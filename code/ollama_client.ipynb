{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be124d0",
   "metadata": {},
   "source": [
    "### Creación de un cliente MCP local con LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b0a7e7",
   "metadata": {},
   "source": [
    "Este Jupyter Notebook te guía en la creación de un cliente MCP (Protocolo de Contexto de Modelo) local que puede comunicarse con una base de datos mediante herramientas expuestas por un servidor MCP, completamente en tu equipo. Sigue las celdas en orden para un tutorial fluido e independiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa nest_asyncio para permitir la ejecución de bucles de eventos anidados en notebooks\n",
    "import nest_asyncio\n",
    "# Aplica el parche para que asyncio funcione correctamente en entornos interactivos como Jupyter\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4002d01",
   "metadata": {},
   "source": [
    "#### Configurar una LLM local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c905405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrador/Documentos/llamaindex-mcp/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validate_default' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'validate_default' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Importa la clase Ollama para usar modelos LLM locales\n",
    "from llama_index.llms.ollama import Ollama\n",
    "# Importa Settings para configurar el modelo globalmente en LlamaIndex\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# Crea una instancia del modelo LLM local especificando el modelo y el timeout\n",
    "llm = Ollama(model=\"llama3.2\", request_timeout=120.0)\n",
    "# Asigna el modelo creado a la configuración global de LlamaIndex\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7027786f",
   "metadata": {},
   "source": [
    "#### Inicializar el cliente MCP y crear el agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4671d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa las clases necesarias para crear un cliente MCP y especificar herramientas\n",
    "from llama_index.tools.mcp import BasicMCPClient, McpToolSpec\n",
    "\n",
    "# Inicializa el cliente MCP apuntando al endpoint del servidor MCP local\n",
    "mcp_client = BasicMCPClient(\"http://localhost:8000/sse\")\n",
    "# Crea el objeto de herramientas MCP, que puede filtrar o limitar las herramientas disponibles\n",
    "mcp_tools = McpToolSpec(client=mcp_client)  # También puedes pasar una lista de herramientas permitidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5b28a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_person \n",
      "    Inserta un nuevo registro en la tabla 'people' de la base de datos.\n",
      "\n",
      "    Permite agregar personas a la base de datos proporcionando nombre, edad y profesión.\n",
      "\n",
      "    Parámetros:\n",
      "        name (str): Nombre de la persona.\n",
      "        age (int): Edad de la persona.\n",
      "        profession (str): Profesión de la persona.\n",
      "\n",
      "    Retorna:\n",
      "        str: Mensaje de éxito o error.\n",
      "\n",
      "    Ejemplo de uso:\n",
      "        >>> add_person('Cristiano Ronaldo', 41, 'Football Player')\n",
      "        \"Persona 'Cristiano Ronaldo' agregada exitosamente\"\n",
      "    \n",
      "get_people \n",
      "    Lee datos de la tabla 'people' de la base de datos usando una consulta SQL SELECT.\n",
      "\n",
      "    Permite recuperar registros de la tabla 'people' según la consulta SQL proporcionada. \n",
      "    Por defecto, devuelve todos los registros.\n",
      "\n",
      "    Parámetros:\n",
      "        query (str, opcional): Consulta SQL SELECT. Por defecto es \"SELECT * FROM people\".\n",
      "\n",
      "    Retorna:\n",
      "        list: Lista de diccionarios con los resultados de la consulta.\n",
      "\n",
      "    Ejemplo de uso:\n",
      "        >>> get_people()\n",
      "        [{\"id\": 1, \"name\": \"John Doe\", \"age\": 30, \"profession\": \"Engineer\"}]\n",
      "\n",
      "        >>> get_people(\"SELECT name, profession FROM people WHERE age < 30\")\n",
      "        [{\"name\": \"Alice Smith\", \"profession\": \"Developer\"}]\n",
      "    \n",
      "get_all_people \n",
      "    Obtiene todas las personas de la base de datos.\n",
      "\n",
      "    Retorna:\n",
      "        list: Lista de todas las personas con sus detalles.\n",
      "    \n",
      "find_person_by_name \n",
      "    Busca personas por nombre en la base de datos.\n",
      "\n",
      "    Parámetros:\n",
      "        name (str): Nombre de la persona a buscar.\n",
      "\n",
      "    Retorna:\n",
      "        list: Lista de personas que coinciden con el nombre.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "tools = await mcp_tools.to_tool_list_async()\n",
    "for tool in tools:\n",
    "    print(tool.metadata.name, tool.metadata.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c97a15",
   "metadata": {},
   "source": [
    "### Definir el indicador del sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f664873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "async def get_agent_ollama(tools: McpToolSpec):\n",
    "    tools = await tools.to_tool_list_async()\n",
    "    agent = FunctionAgent(\n",
    "        name=\"Agent\",\n",
    "        description=\"An agent that can work with Our Database software.\",\n",
    "        tools=tools,\n",
    "        llm=Ollama(model=\"llama3.1\", base_url=\"http://localhost:11434\"),\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94754397",
   "metadata": {},
   "source": [
    "Este mensaje guía al LLM cuando necesita decidir cómo y cuándo llamar a las herramientas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f467bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\\\n",
    "Eres un asistente de IA para la llamada a herramientas.\n",
    "\n",
    "Antes de ayudar a un usuario, necesitas trabajar con herramientas para interactuar con nuestra base de datos.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ad80d0",
   "metadata": {},
   "source": [
    "#### Helper function: `get_agent()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebbc54b",
   "metadata": {},
   "source": [
    "Crea un `FunctionAgent` conectado con la lista de herramientas MCP y el LLM elegido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a477aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.mcp import McpToolSpec\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "async def get_agent_openrouter(tools: McpToolSpec):\n",
    "    tools = await tools.to_tool_list_async()\n",
    "    agent = FunctionAgent(\n",
    "        name=\"Agent\",\n",
    "        description=\"An agent that can work with Our Database software.\",\n",
    "        tools=tools,\n",
    "        llm=OpenAI(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            api_key=\"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\",\n",
    "            api_base=\"https://openrouter.ai/api/v1\"\n",
    "        ),        \n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116f7de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "async def get_agent_ollama(tools: McpToolSpec):\n",
    "    tools = await tools.to_tool_list_async()\n",
    "    agent = FunctionAgent(\n",
    "        name=\"Agent\",\n",
    "        description=\"An agent that can work with Our Database software.\",\n",
    "        tools=tools,\n",
    "        llm=Ollama(model=\"llama3.1:latest\", \n",
    "                   request_timeout=120.0,\n",
    "                   temperature=0.1,\n",
    "                   base_url=\"http://localhost:11434\"),\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747b4baa",
   "metadata": {},
   "source": [
    "#### Helper function: `handle_user_message()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4406c5",
   "metadata": {},
   "source": [
    "Transmite llamadas a herramientas intermedias (para transparencia) y devuelve la respuesta final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37960dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import (\n",
    "    FunctionAgent, \n",
    "    ToolCallResult, \n",
    "    ToolCall)\n",
    "\n",
    "from llama_index.core.workflow import Context\n",
    "\n",
    "async def handle_user_message(\n",
    "    message_content: str,\n",
    "    agent: FunctionAgent,\n",
    "    agent_context: Context,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    handler = agent.run(message_content, ctx=agent_context)\n",
    "    async for event in handler.stream_events():\n",
    "        if verbose and type(event) == ToolCall:\n",
    "            print(f\"Calling tool {event.tool_name} with kwargs {event.tool_kwargs}\")\n",
    "        elif verbose and type(event) == ToolCallResult:\n",
    "            print(f\"Tool {event.tool_name} returned {event.tool_output}\")\n",
    "\n",
    "    response = await handler\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82fbce",
   "metadata": {},
   "source": [
    "#### Initialize the MCP client and build the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1271a983",
   "metadata": {},
   "source": [
    "Apunte el cliente al punto final SSE de su servidor MCP local (el valor predeterminado se muestra a continuación), cree el agente y configure el contexto del agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d7a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from llama_index.tools.mcp import BasicMCPClient, McpToolSpec\n",
    "\n",
    "# Set environment variables for longer timeouts\n",
    "os.environ['OLLAMA_REQUEST_TIMEOUT'] = '360'\n",
    "os.environ['OLLAMA_READ_TIMEOUT'] = '640'\n",
    "\n",
    "# Create MCP client\n",
    "mcp_client = BasicMCPClient(\"http://127.0.0.1:8000/sse\")\n",
    "mcp_tool = McpToolSpec(client=mcp_client)\n",
    "\n",
    "# Your existing code continues...\n",
    "agent = await get_agent_ollama(mcp_tool)\n",
    "agent_context = Context(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5cbe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  \n",
      "Agent:  {\"type\":\"function\",\"function\":\"add_person\", \"parameters\": {\"name\": \"John Doe\", \"age\": \"30\", \"profession\": \"Engineer\"}}\n",
      "User:  add user Luna Valencia, she is 17 years old, she is System engineering student.\n",
      "Calling tool get_all_people with kwargs {}\n",
      "Tool get_all_people returned meta=None content=[TextContent(type='text', text='Error executing tool get_all_people: unable to open database file', annotations=None, meta=None)] structuredContent=None isError=True\n",
      "Agent:  Sorry, no users found.\n",
      "User:  get all users\n",
      "Agent:  {\"type\":\"function\",\"function\":{\"name\": \"add_person\", \"parameters\": {\"name\": \"Luna Valencia\", \"age\": \"17\", \"profession\": \"System engineering student\"}}\n",
      "User:  find Luna\n",
      "Calling tool get_all_people with kwargs {'function': 'get_all_people', 'parameters': {}, 'type': 'function'}\n",
      "Tool get_all_people returned meta=None content=[TextContent(type='text', text='Error executing tool get_all_people: unable to open database file', annotations=None, meta=None)] structuredContent=None isError=True\n",
      "Agent:  {\"name\": \"get_all_users\", \"parameters\": {}}\n",
      "User:  \n",
      "Calling tool get_all_people with kwargs {'function': 'get_all_people', 'parameters': {}, 'type': 'function'}\n",
      "Tool get_all_people returned meta=None content=[TextContent(type='text', text='Error executing tool get_all_people: unable to open database file', annotations=None, meta=None)] structuredContent=None isError=True\n",
      "Agent:  {\"name\": \"get_all_users\", \"parameters\": {}}\n",
      "User:  \n",
      "Agent:  {\"name\": \"get_all_users\", \"parameters\": {}}\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"Enter your message: \")\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "    print(\"User: \", user_input)\n",
    "    response = await handle_user_message(user_input, agent, agent_context, verbose=True)\n",
    "    print(\"Agent: \", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex-mcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
