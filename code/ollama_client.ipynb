{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be124d0",
   "metadata": {},
   "source": [
    "### Creación de un cliente MCP local con LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b0a7e7",
   "metadata": {},
   "source": [
    "Este Jupyter Notebook te guía en la creación de un cliente MCP (Protocolo de Contexto de Modelo) local que puede comunicarse con una base de datos mediante herramientas expuestas por un servidor MCP, completamente en tu equipo. Sigue las celdas en orden para un tutorial fluido e independiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b29e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa nest_asyncio para permitir la ejecución de bucles de eventos anidados en notebooks\n",
    "import nest_asyncio\n",
    "# Aplica el parche para que asyncio funcione correctamente en entornos interactivos como Jupyter\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4002d01",
   "metadata": {},
   "source": [
    "#### Configurar una LLM local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c905405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrador/Documentos/llamaindex-mcp/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validate_default' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'validate_default' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Importa la clase Ollama para usar modelos LLM locales\n",
    "from llama_index.llms.ollama import Ollama\n",
    "# Importa Settings para configurar el modelo globalmente en LlamaIndex\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# Crea una instancia del modelo LLM local especificando el modelo y el timeout\n",
    "llm = Ollama(model=\"llama3.2\", request_timeout=120.0)\n",
    "# Asigna el modelo creado a la configuración global de LlamaIndex\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7027786f",
   "metadata": {},
   "source": [
    "#### Inicializar el cliente MCP y crear el agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4671d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa las clases necesarias para crear un cliente MCP y especificar herramientas\n",
    "from llama_index.tools.mcp import BasicMCPClient, McpToolSpec\n",
    "\n",
    "# Inicializa el cliente MCP apuntando al endpoint del servidor MCP local\n",
    "mcp_client = BasicMCPClient(\"http://localhost:8000/sse\")\n",
    "# Crea el objeto de herramientas MCP, que puede filtrar o limitar las herramientas disponibles\n",
    "mcp_tools = McpToolSpec(client=mcp_client)  # También puedes pasar una lista de herramientas permitidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf5b28a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_person \n",
      "    Inserta un nuevo registro en la tabla 'people' de la base de datos.\n",
      "\n",
      "    Permite agregar personas a la base de datos proporcionando nombre, edad y profesión.\n",
      "\n",
      "    Parámetros:\n",
      "        name (str): Nombre de la persona.\n",
      "        age (int): Edad de la persona.\n",
      "        profession (str): Profesión de la persona.\n",
      "\n",
      "    Retorna:\n",
      "        str: Mensaje de éxito o error.\n",
      "\n",
      "    Ejemplo de uso:\n",
      "        >>> add_person('Cristiano Ronaldo', 41, 'Football Player')\n",
      "        \"Persona 'Cristiano Ronaldo' agregada exitosamente\"\n",
      "    \n",
      "get_people \n",
      "    Lee datos de la tabla 'people' de la base de datos usando una consulta SQL SELECT.\n",
      "\n",
      "    Permite recuperar registros de la tabla 'people' según la consulta SQL proporcionada. \n",
      "    Por defecto, devuelve todos los registros.\n",
      "\n",
      "    Parámetros:\n",
      "        query (str, opcional): Consulta SQL SELECT. Por defecto es \"SELECT * FROM people\".\n",
      "\n",
      "    Retorna:\n",
      "        list: Lista de diccionarios con los resultados de la consulta.\n",
      "\n",
      "    Ejemplo de uso:\n",
      "        >>> get_people()\n",
      "        [{\"id\": 1, \"name\": \"John Doe\", \"age\": 30, \"profession\": \"Engineer\"}]\n",
      "\n",
      "        >>> get_people(\"SELECT name, profession FROM people WHERE age < 30\")\n",
      "        [{\"name\": \"Alice Smith\", \"profession\": \"Developer\"}]\n",
      "    \n",
      "get_all_people \n",
      "    Obtiene todas las personas de la base de datos.\n",
      "\n",
      "    Retorna:\n",
      "        list: Lista de todas las personas con sus detalles.\n",
      "    \n",
      "find_person_by_name \n",
      "    Busca personas por nombre en la base de datos.\n",
      "\n",
      "    Parámetros:\n",
      "        name (str): Nombre de la persona a buscar.\n",
      "\n",
      "    Retorna:\n",
      "        list: Lista de personas que coinciden con el nombre.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "tools = await mcp_tools.to_tool_list_async()\n",
    "for tool in tools:\n",
    "    print(tool.metadata.name, tool.metadata.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c97a15",
   "metadata": {},
   "source": [
    "### Definir el indicador del sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f664873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "async def get_agent_ollama(tools: McpToolSpec):\n",
    "    tools = await tools.to_tool_list_async()\n",
    "    agent = FunctionAgent(\n",
    "        name=\"Agent\",\n",
    "        description=\"An agent that can work with Our Database software.\",\n",
    "        tools=tools,\n",
    "        llm=Ollama(model=\"llama3.1\", base_url=\"http://localhost:11434\"),\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94754397",
   "metadata": {},
   "source": [
    "Este mensaje guía al LLM cuando necesita decidir cómo y cuándo llamar a las herramientas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f467bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\\\n",
    "Eres un asistente de IA para la llamada a herramientas.\n",
    "\n",
    "Antes de ayudar a un usuario, necesitas trabajar con herramientas para interactuar con nuestra base de datos.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ad80d0",
   "metadata": {},
   "source": [
    "#### Helper function: `get_agent()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebbc54b",
   "metadata": {},
   "source": [
    "Crea un `FunctionAgent` conectado con la lista de herramientas MCP y el LLM elegido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2a477aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.mcp import McpToolSpec\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "async def get_agent_openrouter(tools: McpToolSpec):\n",
    "    tools = await tools.to_tool_list_async()\n",
    "    agent = FunctionAgent(\n",
    "        name=\"Agent\",\n",
    "        description=\"An agent that can work with Our Database software.\",\n",
    "        tools=tools,\n",
    "        llm=OpenAI(\n",
    "            model=\"gpt-5-nano\",\n",
    "            api_key=\"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\",\n",
    "            api_base=\"https://openrouter.ai/api/v1\",\n",
    "            max_retries=3,\n",
    "            timeout=120\n",
    "        ),        \n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "116f7de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "async def get_agent_ollama(tools: McpToolSpec):\n",
    "    tools = await tools.to_tool_list_async()\n",
    "    \n",
    "    agent = FunctionAgent(\n",
    "        name=\"Agent\",\n",
    "        description=\"An agent that can work with Our Database software.\",\n",
    "        tools=tools,\n",
    "        llm=Ollama(\n",
    "            model=\"llama3.2:1b\",  # o cualquier modelo que tengas en Ollama\n",
    "            request_timeout=360.0,\n",
    "        ),        \n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747b4baa",
   "metadata": {},
   "source": [
    "#### Helper function: `handle_user_message()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4406c5",
   "metadata": {},
   "source": [
    "Transmite llamadas a herramientas intermedias (para transparencia) y devuelve la respuesta final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37960dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import (\n",
    "    FunctionAgent, \n",
    "    ToolCallResult, \n",
    "    ToolCall)\n",
    "\n",
    "from llama_index.core.workflow import Context\n",
    "\n",
    "async def handle_user_message(\n",
    "    message_content: str,\n",
    "    agent: FunctionAgent,\n",
    "    agent_context: Context,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    handler = agent.run(message_content, ctx=agent_context)\n",
    "    async for event in handler.stream_events():\n",
    "        if verbose and type(event) == ToolCall:\n",
    "            print(f\"Calling tool {event.tool_name} with kwargs {event.tool_kwargs}\")\n",
    "        elif verbose and type(event) == ToolCallResult:\n",
    "            print(f\"Tool {event.tool_name} returned {event.tool_output}\")\n",
    "\n",
    "    response = await handler\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82fbce",
   "metadata": {},
   "source": [
    "#### Initialize the MCP client and build the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1271a983",
   "metadata": {},
   "source": [
    "Apunte el cliente al punto final SSE de su servidor MCP local (el valor predeterminado se muestra a continuación), cree el agente y configure el contexto del agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0d7a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from llama_index.tools.mcp import BasicMCPClient, McpToolSpec\n",
    "\n",
    "# Set environment variables for longer timeouts\n",
    "os.environ['OLLAMA_REQUEST_TIMEOUT'] = '360'\n",
    "os.environ['OLLAMA_READ_TIMEOUT'] = '640'\n",
    "\n",
    "# Create MCP client\n",
    "mcp_client = BasicMCPClient(\"http://127.0.0.1:8000/sse\")\n",
    "mcp_tool = McpToolSpec(client=mcp_client)\n",
    "\n",
    "# Your existing code continues...\n",
    "agent = await get_agent_ollama(mcp_tool)\n",
    "agent_context = Context(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df5cbe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Add John Smith who is 30 years old and works as a Software Developer\n",
      "Calling tool add_person with kwargs {'age': '30', 'name': 'John Smith', 'profession': 'Software Developer'}\n",
      "Tool add_person returned meta=None content=[TextContent(type='text', text=\"Persona 'John Smith' agregada exitosamente\", annotations=None, meta=None)] structuredContent={'result': \"Persona 'John Smith' agregada exitosamente\"} isError=False\n",
      "Calling tool add_person with kwargs {'age': '30', 'name': 'John Smith', 'profession': 'Software Developer'}\n",
      "Tool add_person returned meta=None content=[TextContent(type='text', text=\"Persona 'John Smith' agregada exitosamente\", annotations=None, meta=None)] structuredContent={'result': \"Persona 'John Smith' agregada exitosamente\"} isError=False\n",
      "Calling tool add_person with kwargs {'age': '30', 'name': 'John Smith', 'profession': 'Software Developer'}\n",
      "Tool add_person returned meta=None content=[TextContent(type='text', text=\"Persona 'John Smith' agregada exitosamente\", annotations=None, meta=None)] structuredContent={'result': \"Persona 'John Smith' agregada exitosamente\"} isError=False\n",
      "Calling tool add_person with kwargs {'age': '30', 'name': 'John Smith', 'profession': 'Software Developer'}\n",
      "Tool add_person returned meta=None content=[TextContent(type='text', text=\"Persona 'John Smith' agregada exitosamente\", annotations=None, meta=None)] structuredContent={'result': \"Persona 'John Smith' agregada exitosamente\"} isError=False\n",
      "Calling tool add_person with kwargs {'age': '30', 'name': 'John Smith', 'profession': 'Software Developer'}\n",
      "Tool add_person returned meta=None content=[TextContent(type='text', text=\"Persona 'John Smith' agregada exitosamente\", annotations=None, meta=None)] structuredContent={'result': \"Persona 'John Smith' agregada exitosamente\"} isError=False\n",
      "Calling tool add_person with kwargs {'age': '30', 'name': 'John Smith', 'profession': 'Software Developer'}\n",
      "Tool add_person returned meta=None content=[TextContent(type='text', text=\"Persona 'John Smith' agregada exitosamente\", annotations=None, meta=None)] structuredContent={'result': \"Persona 'John Smith' agregada exitosamente\"} isError=False\n",
      "Calling tool add_person with kwargs {'age': '30', 'name': 'John Smith', 'profession': 'Software Developer'}\n",
      "Tool add_person returned meta=None content=[TextContent(type='text', text=\"Persona 'John Smith' agregada exitosamente\", annotations=None, meta=None)] structuredContent={'result': \"Persona 'John Smith' agregada exitosamente\"} isError=False\n",
      "Calling tool add_person with kwargs {'age': '30', 'name': 'John Smith', 'profession': 'Software Developer'}\n",
      "Tool add_person returned meta=None content=[TextContent(type='text', text=\"Persona 'John Smith' agregada exitosamente\", annotations=None, meta=None)] structuredContent={'result': \"Persona 'John Smith' agregada exitosamente\"} isError=False\n",
      "Calling tool add_person with kwargs {'age': '30', 'name': 'John Smith', 'profession': 'Software Developer'}\n",
      "Tool add_person returned meta=None content=[TextContent(type='text', text=\"Persona 'John Smith' agregada exitosamente\", annotations=None, meta=None)] structuredContent={'result': \"Persona 'John Smith' agregada exitosamente\"} isError=False\n",
      "Calling tool add_person with kwargs {'age': '30', 'name': 'John Smith', 'profession': 'Software Developer'}\n",
      "Tool add_person returned meta=None content=[TextContent(type='text', text=\"Persona 'John Smith' agregada exitosamente\", annotations=None, meta=None)] structuredContent={'result': \"Persona 'John Smith' agregada exitosamente\"} isError=False\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUser: \u001b[39m\u001b[33m\"\u001b[39m, user_input)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m handle_user_message(user_input, agent, agent_context, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAgent: \u001b[39m\u001b[33m\"\u001b[39m, response)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mhandle_user_message\u001b[39m\u001b[34m(message_content, agent, agent_context, verbose)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhandle_user_message\u001b[39m(\n\u001b[32m      9\u001b[39m     message_content: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m     10\u001b[39m     agent: FunctionAgent,\n\u001b[32m     11\u001b[39m     agent_context: Context,\n\u001b[32m     12\u001b[39m     verbose: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     13\u001b[39m ):\n\u001b[32m     14\u001b[39m     handler = agent.run(message_content, ctx=agent_context)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m handler.stream_events():\n\u001b[32m     16\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(event) == ToolCall:\n\u001b[32m     17\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalling tool \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent.tool_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with kwargs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent.tool_kwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/llamaindex-mcp/.venv/lib/python3.12/site-packages/workflows/handler.py:108\u001b[39m, in \u001b[36mWorkflowHandler.stream_events\u001b[39m\u001b[34m(self, expose_internal)\u001b[39m\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WorkflowRuntimeError(msg)\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     ev = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ctx.streaming_queue.get()\n\u001b[32m    110\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ev, InternalDispatchEvent) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m expose_internal:\n\u001b[32m    111\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/anaconda/anaconda3/lib/python3.12/asyncio/queues.py:158\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m._getters.append(getter)\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m getter\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    160\u001b[39m     getter.cancel()  \u001b[38;5;66;03m# Just in case getter is not done yet.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/anaconda/anaconda3/lib/python3.12/asyncio/futures.py:287\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    286\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    289\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/anaconda/anaconda3/lib/python3.12/asyncio/tasks.py:385\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    388\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/anaconda/anaconda3/lib/python3.12/asyncio/futures.py:198\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == _CANCELLED:\n\u001b[32m    197\u001b[39m     exc = \u001b[38;5;28mself\u001b[39m._make_cancelled_error()\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state != _FINISHED:\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.InvalidStateError(\u001b[33m'\u001b[39m\u001b[33mResult is not ready.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"Enter your message: \")\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "    print(\"User: \", user_input)\n",
    "    response = await handle_user_message(user_input, agent, agent_context, verbose=True)\n",
    "    print(\"Agent: \", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex-mcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
