{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be124d0",
   "metadata": {},
   "source": [
    "### Creación de un cliente MCP local con LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b0a7e7",
   "metadata": {},
   "source": [
    "Este Jupyter Notebook te guía en la creación de un cliente MCP (Protocolo de Contexto de Modelo) local que puede comunicarse con una base de datos mediante herramientas expuestas por un servidor MCP, completamente en tu equipo. Sigue las celdas en orden para un tutorial fluido e independiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5b29e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa nest_asyncio para permitir la ejecución de bucles de eventos anidados en notebooks\n",
    "import nest_asyncio\n",
    "# Aplica el parche para que asyncio funcione correctamente en entornos interactivos como Jupyter\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4002d01",
   "metadata": {},
   "source": [
    "#### Configurar una LLM local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4c905405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa la clase Ollama para usar modelos LLM locales\n",
    "from llama_index.llms.ollama import Ollama\n",
    "# Importa Settings para configurar el modelo globalmente en LlamaIndex\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# Crea una instancia del modelo LLM local especificando el modelo y el timeout\n",
    "llm = Ollama(model=\"llama3.2\", request_timeout=120.0)\n",
    "# Asigna el modelo creado a la configuración global de LlamaIndex\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7027786f",
   "metadata": {},
   "source": [
    "#### Inicializar el cliente MCP y crear el agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4671d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa las clases necesarias para crear un cliente MCP y especificar herramientas\n",
    "from llama_index.tools.mcp import BasicMCPClient, McpToolSpec\n",
    "\n",
    "# Inicializa el cliente MCP apuntando al endpoint del servidor MCP local\n",
    "mcp_client = BasicMCPClient(\"http://localhost:8000/sse\")\n",
    "# Crea el objeto de herramientas MCP, que puede filtrar o limitar las herramientas disponibles\n",
    "mcp_tools = McpToolSpec(client=mcp_client)  # También puedes pasar una lista de herramientas permitidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bf5b28a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_person \n",
      "    Inserta un nuevo registro en la tabla 'people' de la base de datos.\n",
      "\n",
      "    Permite agregar personas a la base de datos proporcionando nombre, edad y profesión.\n",
      "\n",
      "    Parámetros:\n",
      "        name (str): Nombre de la persona.\n",
      "        age (int): Edad de la persona.\n",
      "        profession (str): Profesión de la persona.\n",
      "\n",
      "    Retorna:\n",
      "        str: Mensaje de éxito o error.\n",
      "\n",
      "    Ejemplo de uso:\n",
      "        >>> add_person('Cristiano Ronaldo', 41, 'Football Player')\n",
      "        \"Persona 'Cristiano Ronaldo' agregada exitosamente\"\n",
      "    \n",
      "get_people \n",
      "    Lee datos de la tabla 'people' de la base de datos usando una consulta SQL SELECT.\n",
      "\n",
      "    Permite recuperar registros de la tabla 'people' según la consulta SQL proporcionada. \n",
      "    Por defecto, devuelve todos los registros.\n",
      "\n",
      "    Parámetros:\n",
      "        query (str, opcional): Consulta SQL SELECT. Por defecto es \"SELECT * FROM people\".\n",
      "\n",
      "    Retorna:\n",
      "        list: Lista de diccionarios con los resultados de la consulta.\n",
      "\n",
      "    Ejemplo de uso:\n",
      "        >>> get_people()\n",
      "        [{\"id\": 1, \"name\": \"John Doe\", \"age\": 30, \"profession\": \"Engineer\"}]\n",
      "\n",
      "        >>> get_people(\"SELECT name, profession FROM people WHERE age < 30\")\n",
      "        [{\"name\": \"Alice Smith\", \"profession\": \"Developer\"}]\n",
      "    \n",
      "get_all_people \n",
      "    Obtiene todas las personas de la base de datos.\n",
      "\n",
      "    Retorna:\n",
      "        list: Lista de todas las personas con sus detalles.\n",
      "    \n",
      "find_person_by_name \n",
      "    Busca personas por nombre en la base de datos.\n",
      "\n",
      "    Parámetros:\n",
      "        name (str): Nombre de la persona a buscar.\n",
      "\n",
      "    Retorna:\n",
      "        list: Lista de personas que coinciden con el nombre.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "tools = await mcp_tools.to_tool_list_async()\n",
    "for tool in tools:\n",
    "    print(tool.metadata.name, tool.metadata.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c97a15",
   "metadata": {},
   "source": [
    "### Definir el indicador del sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4f664873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "async def get_agent_ollama(tools: McpToolSpec):\n",
    "    tools = await tools.to_tool_list_async()\n",
    "    agent = FunctionAgent(\n",
    "        name=\"Agent\",\n",
    "        description=\"An agent that can work with Our Database software.\",\n",
    "        tools=tools,\n",
    "        llm=Ollama(model=\"llama3.1\", base_url=\"http://localhost:11434\"),\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94754397",
   "metadata": {},
   "source": [
    "Este mensaje guía al LLM cuando necesita decidir cómo y cuándo llamar a las herramientas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f467bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\\\n",
    "Eres un asistente de IA para la llamada a herramientas.\n",
    "\n",
    "Antes de ayudar a un usuario, necesitas trabajar con herramientas para interactuar con nuestra base de datos.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ad80d0",
   "metadata": {},
   "source": [
    "#### Helper function: `get_agent()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebbc54b",
   "metadata": {},
   "source": [
    "Crea un `FunctionAgent` conectado con la lista de herramientas MCP y el LLM elegido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d2a477aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.mcp import McpToolSpec\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "async def get_agent_openrouter(tools: McpToolSpec):\n",
    "    tools = await tools.to_tool_list_async()\n",
    "    agent = FunctionAgent(\n",
    "        name=\"Agent\",\n",
    "        description=\"An agent that can work with Our Database software.\",\n",
    "        tools=tools,\n",
    "        llm=OpenAI(\n",
    "            model=\"gpt-5-nano\",\n",
    "            api_key=\"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\",\n",
    "            api_base=\"https://openrouter.ai/api/v1\",\n",
    "            max_retries=3,\n",
    "            timeout=120\n",
    "        ),        \n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "116f7de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.agent.workflow import (\n",
    "    FunctionAgent, \n",
    "    ToolCallResult, \n",
    "    ToolCall)\n",
    "\n",
    "from llama_index.core.workflow import Context\n",
    "from llama_index.tools.mcp import  McpToolSpec\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Eres un asistente especializado en gestionar una base de datos de personas.\n",
    "\n",
    "INSTRUCCIONES CRÍTICAS:\n",
    "1. PARA AGREGAR PERSONAS: Usa EXACTAMENTE la herramienta 'add_person' con TRES parámetros SEPARADOS:\n",
    "   - name: string con el nombre completo\n",
    "   - age: número entero con la edad  \n",
    "   - profession: string con la profesión\n",
    "\n",
    "2. NUNCA envíes los parámetros como JSON stringificado\n",
    "3. Cada parámetro debe ser enviado individualmente\n",
    "\n",
    "EJEMPLOS CORRECTOS:\n",
    "✅ add_person(name=\"Juan Pérez\", age=30, profession=\"Ingeniero\")\n",
    "✅ add_person(name=\"María García\", age=25, profession=\"Doctora\")\n",
    "\n",
    "EJEMPLOS INCORRECTOS:\n",
    "❌ add_person('{\"name\": \"Juan\", \"age\": 30, \"profession\": \"Ingeniero\"}')\n",
    "❌ add_person(function='{\"name\": \"Juan\", ...}')\n",
    "\n",
    "HERRAMIENTAS DISPONIBLES:\n",
    "- add_person(name: str, age: int, profession: str): Agregar nueva persona\n",
    "- find_person_by_name(name: str): Buscar persona por nombre  \n",
    "- get_all_people(): Obtener todas las personas\n",
    "\n",
    "Responde en español de manera clara y útil.\n",
    "\"\"\"\n",
    "\n",
    "async def get_agent_ollama(tools: McpToolSpec):\n",
    "    tools_list = await tools.to_tool_list_async()\n",
    "    \n",
    "    # Debug: print available tools\n",
    "    print(\"🔧 Herramientas MCP disponibles:\")\n",
    "    for tool in tools_list:\n",
    "        print(f\"  - {tool.metadata.name}: {tool.metadata.description}\")\n",
    "    \n",
    "    agent = FunctionAgent(\n",
    "        tools=tools_list,\n",
    "        llm=Ollama(\n",
    "            model=\"llama3.2:3b\",\n",
    "            request_timeout=360.0,\n",
    "        ),        \n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "        verbose=True  # Para ver qué está haciendo el agente\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747b4baa",
   "metadata": {},
   "source": [
    "#### Helper function: `handle_user_message()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4406c5",
   "metadata": {},
   "source": [
    "Transmite llamadas a herramientas intermedias (para transparencia) y devuelve la respuesta final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "37960dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def handle_user_message(\n",
    "    message_content: str,\n",
    "    agent: FunctionAgent,\n",
    "    agent_context: Context,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    handler = agent.run(message_content, ctx=agent_context)\n",
    "    async for event in handler.stream_events():\n",
    "        if verbose and type(event) == ToolCall:\n",
    "            print(f\"Calling tool {event.tool_name} with kwargs {event.tool_kwargs}\")\n",
    "        elif verbose and type(event) == ToolCallResult:\n",
    "            print(f\"Tool {event.tool_name} returned {event.tool_output}\")\n",
    "\n",
    "    response = await handler\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82fbce",
   "metadata": {},
   "source": [
    "#### Initialize the MCP client and build the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1271a983",
   "metadata": {},
   "source": [
    "Apunte el cliente al punto final SSE de su servidor MCP local (el valor predeterminado se muestra a continuación), cree el agente y configure el contexto del agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b0d7a8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Herramientas MCP disponibles:\n",
      "  - add_person: \n",
      "    Inserta un nuevo registro en la tabla 'people' de la base de datos.\n",
      "\n",
      "    Permite agregar personas a la base de datos proporcionando nombre, edad y profesión.\n",
      "\n",
      "    Parámetros:\n",
      "        name (str): Nombre de la persona.\n",
      "        age (int): Edad de la persona.\n",
      "        profession (str): Profesión de la persona.\n",
      "\n",
      "    Retorna:\n",
      "        str: Mensaje de éxito o error.\n",
      "\n",
      "    Ejemplo de uso:\n",
      "        >>> add_person('Cristiano Ronaldo', 41, 'Football Player')\n",
      "        \"Persona 'Cristiano Ronaldo' agregada exitosamente\"\n",
      "    \n",
      "  - get_people: \n",
      "    Lee datos de la tabla 'people' de la base de datos usando una consulta SQL SELECT.\n",
      "\n",
      "    Permite recuperar registros de la tabla 'people' según la consulta SQL proporcionada. \n",
      "    Por defecto, devuelve todos los registros.\n",
      "\n",
      "    Parámetros:\n",
      "        query (str, opcional): Consulta SQL SELECT. Por defecto es \"SELECT * FROM people\".\n",
      "\n",
      "    Retorna:\n",
      "        list: Lista de diccionarios con los resultados de la consulta.\n",
      "\n",
      "    Ejemplo de uso:\n",
      "        >>> get_people()\n",
      "        [{\"id\": 1, \"name\": \"John Doe\", \"age\": 30, \"profession\": \"Engineer\"}]\n",
      "\n",
      "        >>> get_people(\"SELECT name, profession FROM people WHERE age < 30\")\n",
      "        [{\"name\": \"Alice Smith\", \"profession\": \"Developer\"}]\n",
      "    \n",
      "  - get_all_people: \n",
      "    Obtiene todas las personas de la base de datos.\n",
      "\n",
      "    Retorna:\n",
      "        list: Lista de todas las personas con sus detalles.\n",
      "    \n",
      "  - find_person_by_name: \n",
      "    Busca personas por nombre en la base de datos.\n",
      "\n",
      "    Parámetros:\n",
      "        name (str): Nombre de la persona a buscar.\n",
      "\n",
      "    Retorna:\n",
      "        list: Lista de personas que coinciden con el nombre.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from llama_index.tools.mcp import BasicMCPClient, McpToolSpec\n",
    "\n",
    "# Set environment variables for longer timeouts\n",
    "os.environ['OLLAMA_REQUEST_TIMEOUT'] = '360'\n",
    "os.environ['OLLAMA_READ_TIMEOUT'] = '640'\n",
    "\n",
    "# Create MCP client\n",
    "mcp_client = BasicMCPClient(\"http://127.0.0.1:8000/sse\")\n",
    "mcp_tool = McpToolSpec(client=mcp_client)\n",
    "\n",
    "# Your existing code continues...\n",
    "agent = await get_agent_ollama(mcp_tool)\n",
    "agent_context = Context(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5cbe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  add Ana 25 Doctor\n",
      "Running step init_run\n",
      "Step init_run produced event AgentInput\n",
      "Running step setup_agent\n",
      "Step setup_agent produced event AgentSetup\n",
      "Running step run_agent_step\n",
      "Step run_agent_step produced event AgentOutput\n",
      "Running step parse_agent_output\n",
      "Step parse_agent_output produced no event\n",
      "Running step call_tool\n",
      "Calling tool add_person with kwargs {'age': '25', 'name': 'Ana', 'profession': 'Doctor'}\n",
      "Step call_tool produced event ToolCallResult\n",
      "Tool add_person returned meta=None content=[TextContent(type='text', text=\"Persona 'Ana' agregada exitosamente\", annotations=None, meta=None)] structuredContent={'result': \"Persona 'Ana' agregada exitosamente\"} isError=False\n",
      "Running step aggregate_tool_results\n",
      "Step aggregate_tool_results produced event AgentInput\n",
      "Running step setup_agent\n",
      "Step setup_agent produced event AgentSetup\n",
      "Running step run_agent_step\n",
      "Step run_agent_step produced event AgentOutput\n",
      "Running step parse_agent_output\n",
      "Step parse_agent_output produced event StopEvent\n",
      "Agent:  La persona Ana de 25 años con profesión de Doctora ha sido agregada a la base de datos con éxito.\n",
      "User:  find ana\n",
      "Running step init_run\n",
      "Step init_run produced event AgentInput\n",
      "Running step setup_agent\n",
      "Step setup_agent produced event AgentSetup\n",
      "Running step run_agent_step\n",
      "Step run_agent_step produced event AgentOutput\n",
      "Running step parse_agent_output\n",
      "Step parse_agent_output produced no event\n",
      "Running step call_tool\n",
      "Calling tool find_person_by_name with kwargs {'name': 'Ana'}\n",
      "Step call_tool produced event ToolCallResult\n",
      "Tool find_person_by_name returned meta=None content=[TextContent(type='text', text='{\\n  \"id\": 24,\\n  \"name\": \"Ana\",\\n  \"age\": 25,\\n  \"profession\": \"Doctor\"\\n}', annotations=None, meta=None)] structuredContent=None isError=False\n",
      "Running step aggregate_tool_results\n",
      "Step aggregate_tool_results produced event AgentInput\n",
      "Running step setup_agent\n",
      "Step setup_agent produced event AgentSetup\n",
      "Running step run_agent_step\n",
      "Step run_agent_step produced event AgentOutput\n",
      "Running step parse_agent_output\n",
      "Step parse_agent_output produced event StopEvent\n",
      "Agent:  La persona Ana se encuentra en la base de datos y tiene una edad de 25 años y una profesión de Doctora. Su identificador es 24.\n",
      "User:  get all people\n",
      "Running step init_run\n",
      "Step init_run produced event AgentInput\n",
      "Running step setup_agent\n",
      "Step setup_agent produced event AgentSetup\n",
      "Running step run_agent_step\n",
      "Step run_agent_step produced event AgentOutput\n",
      "Running step parse_agent_output\n",
      "Step parse_agent_output produced no event\n",
      "Running step call_tool\n",
      "Calling tool get_all_people with kwargs {}\n",
      "Step call_tool produced event ToolCallResult\n",
      "Tool get_all_people returned meta=None content=[TextContent(type='text', text='{\\n  \"id\": 1,\\n  \"name\": \"Rafael Nadal\",\\n  \"age\": 39,\\n  \"profession\": \"Tennis Player\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 2,\\n  \"name\": \"Lionel Messi\",\\n  \"age\": 39,\\n  \"profession\": \"Football Player\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 3,\\n  \"name\": \"Cristiano Ronaldo\",\\n  \"age\": 41,\\n  \"profession\": \"Football Player\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 4,\\n  \"name\": \"Cristiano Ronaldo\",\\n  \"age\": 41,\\n  \"profession\": \"Football Player\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 5,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 6,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 7,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 8,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 9,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 10,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 11,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 12,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 13,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 14,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 15,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 16,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 17,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 18,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 19,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 20,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 21,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 22,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 23,\\n  \"name\": \"John Smith\",\\n  \"age\": 30,\\n  \"profession\": \"Software Developer\"\\n}', annotations=None, meta=None), TextContent(type='text', text='{\\n  \"id\": 24,\\n  \"name\": \"Ana\",\\n  \"age\": 25,\\n  \"profession\": \"Doctor\"\\n}', annotations=None, meta=None)] structuredContent=None isError=False\n",
      "Running step aggregate_tool_results\n",
      "Step aggregate_tool_results produced event AgentInput\n",
      "Running step setup_agent\n",
      "Step setup_agent produced event AgentSetup\n",
      "Running step run_agent_step\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"Enter your message: \")\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "    print(\"User: \", user_input)\n",
    "    response = await handle_user_message(user_input, agent, agent_context, verbose=True)\n",
    "    print(\"Agent: \", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex-mcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
